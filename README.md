# ğŸ”¬ Whisper vs Faster-Whisper Benchmarking

An **R&D-focused benchmarking repository** comparing **OpenAI Whisper** and **SYSTRAN Faster-Whisper** for local Speech-to-Text inference.

## ğŸ¯ Purpose

Evaluate **accuracy, performance, and inference behavior** of:
- Whisper Large-V2
- Faster-Whisper Large-V2

All experiments are run **locally** using real audio samples.

## ğŸ§ª Experiments Covered

- Inference comparison between Whisper and Faster-Whisper
- Audio format handling (OPUS â†’ MP3)
- Language detection using Whisper base models
- Batch and single-audio transcription workflows

## ğŸ“‚ Repository Structure

- `STT_Models_Comparison.ipynb`  
  â†’ Side-by-side inference comparison (Whisper vs Faster-Whisper)

- `Whisper_Base_Model_Language_Detection.ipynb`  
  â†’ Language detection experiments using Whisper base model

- `Whisper_Speech-to-Text.py`  
  â†’ Script-based STT inference

- `opus_converter_mp3.py`  
  â†’ Audio format conversion utility

- `audio/`  
  â†’ Sample audio files used for evaluation

## ğŸ› ï¸ Tech Stack

- Python  
- OpenAI Whisper  
- SYSTRAN Faster-Whisper  
- Jupyter Notebooks  
- FFmpeg

## ğŸ§  What This Demonstrates

- Model evaluation and benchmarking skills
- Practical understanding of speech models
- Performance-aware ML experimentation
- R&D workflows for applied ML systems

## ğŸ“Œ Use Cases

- Selecting STT models for production systems
- Performance vs accuracy trade-off analysis
- Research and experimentation with speech models


